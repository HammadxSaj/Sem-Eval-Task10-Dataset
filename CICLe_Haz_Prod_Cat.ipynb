{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy torch pandas scikit-learn crepes transformers tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:07:54.718870Z","iopub.execute_input":"2024-11-27T09:07:54.719318Z","iopub.status.idle":"2024-11-27T09:08:06.029884Z","shell.execute_reply.started":"2024-11-27T09:07:54.719281Z","shell.execute_reply":"2024-11-27T09:08:06.028661Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nCollecting crepes\n  Downloading crepes-0.7.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading crepes-0.7.1-py3-none-any.whl (29 kB)\nInstalling collected packages: crepes\nSuccessfully installed crepes-0.7.1\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!wget -P /kaggle/working -nc \"https://raw.githubusercontent.com/HammadxSaj/Sem-Eval-Task10-Dataset/refs/heads/main/final_cleaned_train.csv\"\n!wget -P /kaggle/working -nc \"https://raw.githubusercontent.com/HammadxSaj/Sem-Eval-Task10-Dataset/refs/heads/main/final_cleaned_validation.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:08:10.853694Z","iopub.execute_input":"2024-11-27T09:08:10.854138Z","iopub.status.idle":"2024-11-27T09:08:13.041334Z","shell.execute_reply.started":"2024-11-27T09:08:10.854105Z","shell.execute_reply":"2024-11-27T09:08:13.039972Z"}},"outputs":[{"name":"stdout","text":"File '/kaggle/working/final_cleaned_train.csv' already there; not retrieving.\n\nFile '/kaggle/working/final_cleaned_validation.csv' already there; not retrieving.\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndata = pd.read_csv('/kaggle/working/final_cleaned_train.csv', index_col=0)\ndata.sample()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:08:13.042970Z","iopub.execute_input":"2024-11-27T09:08:13.043321Z","iopub.status.idle":"2024-11-27T09:08:13.238769Z","shell.execute_reply.started":"2024-11-27T09:08:13.043289Z","shell.execute_reply":"2024-11-27T09:08:13.237747Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"      month  day country                                              title  \\\nyear                                                                          \n2015     10   23      uk  Mr Naga Hot Pepper Pickle recalled due to unde...   \n\n                                                   text hazard-category  \\\nyear                                                                      \n2015  Shahnaz Food Products Ltd is recalling jars of...       allergens   \n\n           product-category                        hazard          product  \nyear                                                                        \n2015  fruits and vegetables  mustard and products thereof  pickled peppers  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>month</th>\n      <th>day</th>\n      <th>country</th>\n      <th>title</th>\n      <th>text</th>\n      <th>hazard-category</th>\n      <th>product-category</th>\n      <th>hazard</th>\n      <th>product</th>\n    </tr>\n    <tr>\n      <th>year</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015</th>\n      <td>10</td>\n      <td>23</td>\n      <td>uk</td>\n      <td>Mr Naga Hot Pepper Pickle recalled due to unde...</td>\n      <td>Shahnaz Food Products Ltd is recalling jars of...</td>\n      <td>allergens</td>\n      <td>fruits and vegetables</td>\n      <td>mustard and products thereof</td>\n      <td>pickled peppers</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# select input and label from data:\nX = data['title']\ny = data[['hazard-category', 'product-category']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:08:13.240199Z","iopub.execute_input":"2024-11-27T09:08:13.240524Z","iopub.status.idle":"2024-11-27T09:08:13.253558Z","shell.execute_reply.started":"2024-11-27T09:08:13.240493Z","shell.execute_reply":"2024-11-27T09:08:13.252553Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_dev, y_train, y_dev = {}, {}, {}, {}\n\n# create train and development sets:\nfor column in y.columns:\n    X_train[column], X_dev[column], y_train[column], y_dev[column] = train_test_split(X.values, y[column].values, test_size=.2, shuffle=True, random_state=42, stratify=y[column])\n    print(column.upper())\n    print('  Size of development set:', X_dev[column].shape)\n    print('  Size of train set:      ', X_train[column].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:08:13.254901Z","iopub.execute_input":"2024-11-27T09:08:13.255279Z","iopub.status.idle":"2024-11-27T09:08:13.284277Z","shell.execute_reply.started":"2024-11-27T09:08:13.255248Z","shell.execute_reply":"2024-11-27T09:08:13.282983Z"}},"outputs":[{"name":"stdout","text":"HAZARD-CATEGORY\n  Size of development set: (1194,)\n  Size of train set:       (4772,)\nPRODUCT-CATEGORY\n  Size of development set: (1194,)\n  Size of train set:       (4772,)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# create and train input embedding:\ntfidf = TfidfVectorizer().fit(X)\n\n# since TfidfVectorizer.transform(...) returns a sparse matrix which 'crepes'\n# does not handle well, we use the following utility function to encode our texts:\nphi = lambda x: tfidf.transform(x).toarray()\n\n# print a sample of the vocabulary to show that we learned something:\nlist(tfidf.vocabulary_.keys())[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:08:13.285586Z","iopub.execute_input":"2024-11-27T09:08:13.286061Z","iopub.status.idle":"2024-11-27T09:08:13.396647Z","shell.execute_reply.started":"2024-11-27T09:08:13.286022Z","shell.execute_reply":"2024-11-27T09:08:13.395540Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['recall', 'notification', 'fsis', '024', '94']"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# create label to one-hot and reverse dictionaries:\nid2label = {column:np.unique(y[column]) for column in y.columns}\nlabel2id = {column:{l:i for i, l in enumerate(id2label[column])} for column in y.columns}\n\n# show label-id mapping:\nlabel2id['hazard-category']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:08:13.398030Z","iopub.execute_input":"2024-11-27T09:08:13.398464Z","iopub.status.idle":"2024-11-27T09:08:13.412183Z","shell.execute_reply.started":"2024-11-27T09:08:13.398421Z","shell.execute_reply":"2024-11-27T09:08:13.411331Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'allergens': 0,\n 'biological': 1,\n 'chemical': 2,\n 'food additives and flavourings': 3,\n 'foreign bodies': 4,\n 'fraud': 5,\n 'migration': 6,\n 'organoleptic aspects': 7,\n 'other hazard': 8,\n 'packaging defect': 9}"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"label2id['product-category']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:08:13.413282Z","iopub.execute_input":"2024-11-27T09:08:13.413681Z","iopub.status.idle":"2024-11-27T09:08:13.425961Z","shell.execute_reply.started":"2024-11-27T09:08:13.413636Z","shell.execute_reply":"2024-11-27T09:08:13.425011Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'alcoholic beverages': 0,\n 'cereals and bakery products': 1,\n 'cocoa and cocoa preparations, coffee and tea': 2,\n 'confectionery': 3,\n 'dietetic foods, food supplements, fortified foods': 4,\n 'fats and oils': 5,\n 'feed materials': 6,\n 'food additives and flavourings': 7,\n 'food contact materials': 8,\n 'fruits and vegetables': 9,\n 'herbs and spices': 10,\n 'honey and royal jelly': 11,\n 'ices and desserts': 12,\n 'meat, egg and dairy products': 13,\n 'non-alcoholic beverages': 14,\n 'nuts, nut products and seeds': 15,\n 'other food product / mixed': 16,\n 'pet feed': 17,\n 'prepared dishes and snacks': 18,\n 'seafood': 19,\n 'soups, broths, sauces and condiments': 20,\n 'sugars and syrups': 21}"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"from crepes import WrapClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# create a conformal base classifiers based on Logistic Regression:\nbase_classifiers = {column:WrapClassifier(LogisticRegression()) for column in y.columns}\n\nfor column in base_classifiers:\n    # train the base classifier:\n    base_classifiers[column].fit(\n        phi(X_train[column]),\n        [label2id[column][l] for l in y_train[column]]\n    )\n\n    # calibrate the base classifier:\n    base_classifiers[column].calibrate(\n        phi(X_dev[column]),\n        [label2id[column][l] for l in y_dev[column]],\n        class_cond=True\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:08:13.427357Z","iopub.execute_input":"2024-11-27T09:08:13.427764Z","iopub.status.idle":"2024-11-27T09:09:09.990697Z","shell.execute_reply.started":"2024-11-27T09:08:13.427732Z","shell.execute_reply":"2024-11-27T09:09:09.989287Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import getpass\nfrom huggingface_hub import login\nlogin(getpass.getpass('Enter your huggingface API-key:'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:09:09.992067Z","iopub.execute_input":"2024-11-27T09:09:09.992482Z","iopub.status.idle":"2024-11-27T09:24:36.235553Z","shell.execute_reply.started":"2024-11-27T09:09:09.992439Z","shell.execute_reply":"2024-11-27T09:24:36.234365Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your huggingface API-key: ········\n"},{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import transformers\nimport torch\n\n# create llm pipeline:\nllm = transformers.pipeline(\n    \"text-generation\",\n    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n    model_kwargs={\"torch_dtype\": torch.bfloat16},\n    device_map=\"auto\"\n)\n\n# Get special tokens for later:\nbos_token_id = llm.tokenizer.convert_tokens_to_ids('<|begin_of_text|>')\neos_token_id = llm.tokenizer.convert_tokens_to_ids('<|eot_id|>')\npad_token_id = llm.tokenizer.convert_tokens_to_ids('<|eot_id|>')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:24:36.236938Z","iopub.execute_input":"2024-11-27T09:24:36.237277Z","iopub.status.idle":"2024-11-27T09:31:28.114874Z","shell.execute_reply.started":"2024-11-27T09:24:36.237246Z","shell.execute_reply":"2024-11-27T09:31:28.113856Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93589abfec4942a4ab90ae52868c3c5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"980ce008601e49e0a68324015f22e456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3c04ddf5d8b4a0a8d210550969599ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c39863ae14ee4646b6791aeaafd432a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4213b8c58d14290ae68c2d868ac37b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a27f01dfbb8a473ebe7f8dc77a6fb91e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00eaba6b6f074edfb74d3e2565008ef6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca2e59e4a3ff4eda9fdb1060b3fc227b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e4842749af14f878c4f56258fbec4cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f88a7b62e2e41aa93c72efc4c9d7ff9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3974cd1c4974e329498d4b12304e42c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"131da19de746489a840c21bdc69a29b9"}},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"from sklearn.metrics import pairwise_distances\n\ndef get_few_shot_examples(column, text, examples_per_class=2):\n    examples = []\n\n    # generate conformal prediction set:\n    prediction_set = id2label[column][base_classifiers[column].predict_set(phi([text])).astype(bool)[0]]\n    \n    for y in prediction_set:\n        # get texts in current class:\n        texts = X_train[column][y_train[column] == y]\n\n        # generate embeddings of texts in class:\n        embeddings = phi([text] + texts.tolist())\n\n        # calculate cosine-similarity:\n        similarity = (1. - pairwise_distances(embeddings, metric='cosine'))[1:,0]\n\n        # get closest sample of training data based on embeddings:\n        for j in np.argsort(similarity)[::-1][:examples_per_class]:\n            examples.append((texts[j], y, similarity[j]))\n\n    # sort samples based on embedding from training data:\n    examples.sort(key=lambda e: e[2], reverse=True)\n\n    return examples\n\n# print sample output:\nsamples = get_few_shot_examples('hazard-category', X_dev['hazard-category'][0])\nsamples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:31:28.116299Z","iopub.execute_input":"2024-11-27T09:31:28.116915Z","iopub.status.idle":"2024-11-27T09:31:29.284133Z","shell.execute_reply.started":"2024-11-27T09:31:28.116881Z","shell.execute_reply":"2024-11-27T09:31:29.283045Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[('J. L. King & Co—Tuna Pasta Salad', 'biological', 0.35513942995404624),\n ('Coles—Garden Vegetable Pasta Sauce', 'foreign bodies', 0.3419897147547253),\n ('Enrico’s Kitchen Pty Ltd—Frozen pizza and pasta products',\n  'foreign bodies',\n  0.3336328866991509),\n ('Avanza Pasta, LLC Recalls Beef and Poultry Products  Produced Without Benefit of Inspection',\n  'fraud',\n  0.3164180527682221),\n ('Avanza Pasta, LLC Recalls Beef and Poultry Products  Produced Without Benefit of Inspection',\n  'fraud',\n  0.3164180527682221),\n ('Recall of Me2you Italian Pasta Salad due to the Possible Presence of Listeria monocytogenes',\n  'biological',\n  0.26290953289773256),\n (\"Recall of “Bellamy's Organic - Organic Brown Rice Pasta Stars”\",\n  'chemical',\n  0.2357641851388549),\n ('Various brands of juice products recalled due to off odour',\n  'organoleptic aspects',\n  0.1527461141783999),\n ('baketime ltd recalls various branded biscuit, snack and confectionery products',\n  'other hazard',\n  0.1339119818958855),\n ('Jumbo Importers recalls various KOO canned products because of defective cans',\n  'packaging defect',\n  0.11598107281023029),\n ('west london sandwiches recalls various sandwiches because the products have been produced in unhygienic conditions',\n  'other hazard',\n  0.09707723593155526),\n ('g j wholesale alcohol products', 'chemical', 0.07789442765118237),\n ('Valley Fine Foods Recalls Meat and Poultry Products due to Possible Adulteration',\n  'organoleptic aspects',\n  0.05925450719586145),\n ('Withdrawal of Various Nylon Kitchen Utensils due to Chemical Migration above the EU legal limit',\n  'migration',\n  0.0566912614821552),\n (\"Burger's Ozark Country Cured Recalls Poultry Products Due To Misbranding\",\n  'food additives and flavourings',\n  0.05202339982933901),\n ('Wah Lien Trading Pty Ltd—Konnyaku Jelly Powder',\n  'food additives and flavourings',\n  0.0),\n ('Yummy plate, Happy dots, blue', 'migration', 0.0),\n ('SPC Ardmona—Ardmona Whole Peeled Vine Ripened Tomatoes',\n  'packaging defect',\n  0.0)]"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"def create_prompt(column, text, examples):\n    # helper function replacing quotation marks in the text:\n    replace_qm = lambda s: s.replace('\"', \"'\")\n\n    # create context:\n    context = f'We are looking for food {column.split(\"-\")[0]}s in texts. Here are some labeled examples sorted from most probable to least probable:\\n'\n\n    for x, y, _ in examples:\n        context += f'\\n\"{replace_qm(x)}\" => {y}'\n\n    return {\"role\": \"user\", \"content\": f'{context}\\n\\nPlease predict the correct class for the following sample. Only provide the class label.\\n\\n\"{replace_qm(text)}\" => '}\n\n# print sample prompt:\nprint(create_prompt('hazard-category', X_dev['hazard-category'][0], samples)[\"content\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:31:29.285465Z","iopub.execute_input":"2024-11-27T09:31:29.286019Z","iopub.status.idle":"2024-11-27T09:31:29.295735Z","shell.execute_reply.started":"2024-11-27T09:31:29.285969Z","shell.execute_reply":"2024-11-27T09:31:29.294755Z"}},"outputs":[{"name":"stdout","text":"We are looking for food hazards in texts. Here are some labeled examples sorted from most probable to least probable:\n\n\"J. L. King & Co—Tuna Pasta Salad\" => biological\n\"Coles—Garden Vegetable Pasta Sauce\" => foreign bodies\n\"Enrico’s Kitchen Pty Ltd—Frozen pizza and pasta products\" => foreign bodies\n\"Avanza Pasta, LLC Recalls Beef and Poultry Products  Produced Without Benefit of Inspection\" => fraud\n\"Avanza Pasta, LLC Recalls Beef and Poultry Products  Produced Without Benefit of Inspection\" => fraud\n\"Recall of Me2you Italian Pasta Salad due to the Possible Presence of Listeria monocytogenes\" => biological\n\"Recall of “Bellamy's Organic - Organic Brown Rice Pasta Stars”\" => chemical\n\"Various brands of juice products recalled due to off odour\" => organoleptic aspects\n\"baketime ltd recalls various branded biscuit, snack and confectionery products\" => other hazard\n\"Jumbo Importers recalls various KOO canned products because of defective cans\" => packaging defect\n\"west london sandwiches recalls various sandwiches because the products have been produced in unhygienic conditions\" => other hazard\n\"g j wholesale alcohol products\" => chemical\n\"Valley Fine Foods Recalls Meat and Poultry Products due to Possible Adulteration\" => organoleptic aspects\n\"Withdrawal of Various Nylon Kitchen Utensils due to Chemical Migration above the EU legal limit\" => migration\n\"Burger's Ozark Country Cured Recalls Poultry Products Due To Misbranding\" => food additives and flavourings\n\"Wah Lien Trading Pty Ltd—Konnyaku Jelly Powder\" => food additives and flavourings\n\"Yummy plate, Happy dots, blue\" => migration\n\"SPC Ardmona—Ardmona Whole Peeled Vine Ripened Tomatoes\" => packaging defect\n\nPlease predict the correct class for the following sample. Only provide the class label.\n\n\"Mary's Pasta Products—various pasta products\" => \n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# load test set:\ndata_test = pd.read_csv('/kaggle/working/final_cleaned_validation.csv', index_col=0)\nX_test = data_test['title'].values\n\ndata_test.sample()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T09:31:29.297686Z","iopub.execute_input":"2024-11-27T09:31:29.298444Z","iopub.status.idle":"2024-11-27T09:31:29.374605Z","shell.execute_reply.started":"2024-11-27T09:31:29.298394Z","shell.execute_reply":"2024-11-27T09:31:29.373417Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"      month  day country                                              title  \\\nyear                                                                          \n2019      4    2      us  Wakefern Food Corp. Voluntarily Recalls Wholes...   \n\n                                                   text  \nyear                                                     \n2019  Wakefern Food Corp. has initiated a voluntary ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>month</th>\n      <th>day</th>\n      <th>country</th>\n      <th>title</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>year</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019</th>\n      <td>4</td>\n      <td>2</td>\n      <td>us</td>\n      <td>Wakefern Food Corp. Voluntarily Recalls Wholes...</td>\n      <td>Wakefern Food Corp. has initiated a voluntary ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\n# predict test set:\nfor column in base_classifiers:\n    # add new column to dataframe:\n    data_test[column] = ['']*len(data_test)\n    mask = data_test.columns == column\n\n    for i, x in enumerate(tqdm(X_test, desc='Assessing texts')):\n        # get 2 most similar texts in the training data:\n        examples = get_few_shot_examples(column, x)\n        \n        if len(examples) > 1:\n            # create prompt:\n            prompt = create_prompt(column, x, examples)\n    \n            # prompt LLM:\n            data_test.iloc[i, mask] = llm([prompt],\n                bos_token_id=bos_token_id,\n                eos_token_id=eos_token_id,\n                pad_token_id=pad_token_id,\n                max_new_tokens=32,\n                do_sample=False,\n                temperature=None,\n                top_p=None\n            )[0][\"generated_text\"][-1][\"content\"]\n    \n        else: data_test.iloc[i, mask] = examples[0]\n\ndata_test.sample()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_test[['hazard-category', 'product-category']].to_csv('submission.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}